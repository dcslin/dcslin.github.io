# Coding

## 对数分布

变化以当前乘以一个系数体现的数据通常服从对数分布。例如，$x_1 = x_0 \times k$，$x_2 = x_1 \times k$，如股价等。

## 中心极限原理/大数定理

## normal分布

每一次都是独立随机抽取，不断累积的和

---

## 特征向量

张成空间，维数，线性映射，零空间，多项式，特征值，特征向量，内积，

---

## VC维

## 没有免费午餐定理

## pac 定理, boosting, 正则化，在线学习，生成模型，隐变量，EM算法，贝叶斯推理，

## 线性回归

线性回归的目标是找到一条最能表达样本数据的直线，通常形式为 $y = wx$。我们定义损失函数为：

$$
\text{loss} = \sum (y_i - y)^2
$$

通过最小化损失函数（即 $\min(\text{loss})$），可以求得最优参数 $w$。

---

## 极大似然估计

假设每个数据点都是从一个高斯分布中抽取出来的。所有点的概率连乘积越大，说明这组参数越能代表数据。对于线性回归，假设每个样本的 $y$ 都依赖于 $wx$，即 $y$ 的概率分布为 $N(y|wx, \sigma^2)$。将其代入极大似然估计后，可以化简为与残差平方和相同的形式。

---

## 采样与估计

- **采样（Sampling）**：从概率分布中抽取样本，即已知概率分布，生成数据。
- **估计（Estimation）**：根据已有样本数据，反推出概率分布参数，即通过数据推断分布。

采样和估计是相反的过程。概率（Probability）用于已知分布求样本的可能性，似然（Likelihood）用于已知样本估计分布参数，两者也是逆向关系。

## SVM

## PCA

## KL divergent

---

clique团，
贝叶斯网络，马尔可夫链，
推断interfence，
精确推断：变量消除，团树算法，信念传播
近似推断：蒙特卡洛，mcmc，变分推断，置信传播
学习learning
参数学习：极大似然，贝叶斯参数，em算法
结构学习
条件独立性检验
拓展模型：隐马尔可夫链，条件随机场，因子图，GAN

